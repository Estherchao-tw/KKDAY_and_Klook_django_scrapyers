# KKDAY_django_scrapyers
python çˆ¬èŸ²ç¶²ç«™è³‡æ–™ å°‡çµæœæ”¾åœ¨django è‡ªè£½ç¶²ç«™
ç¨‹å¼é€éç‰©ä»¶å°å‘(Object-oriented)æ–¹æ³•è£½ä½œ 

        
## demo

https://github.com/Estherchao-tw/KKDAY_and_Klook_django_scrapyers/assets/74496288/396037c2-0d81-4898-b689-4b2bf3eacb6b



## å»ºç«‹django æ‡‰ç”¨ç¨‹å¼
### settings.py (in trip folder)


**Application definition**

ç‚ºäº†è¦è®“å°ˆæ¡ˆä¸»ç¨‹å¼èƒ½å¤ èªå¾—æ‡‰ç”¨ç¨‹å¼ï¼Œå°±éœ€è¦é–‹å•Ÿå°ˆæ¡ˆä¸»ç¨‹å¼ä¸‹çš„settings.pyæª”æ¡ˆï¼Œåœ¨NSTALL_APPSçš„åœ°æ–¹ï¼ŒåŠ å…¥æ‡‰ç”¨ç¨‹å¼çš„è¨­å®šæª”

        
    'tickets.apps.TicketsConfig',

## å»ºç«‹Djanog æ‡‰ç”¨ç¨‹å¼ç¶²å€
### urls.py (in tickets pockets)
è¨­å®šä¸€çµ„ç¶²å€ï¼Œè®“ä½¿ç”¨è€…é€éé€™å€‹ç€è¦½å™¨ä¾†é€²è¡Œè«‹æ±‚(Request)
ex: https://127.0.0.1:80/index

        from django.urls import path
        from . import views

        app_name = "tickets"
 
        urlpatterns = [
            path('',views.index, name='index')
        ]
        
### urls.py (in trip pocketsï¼Œå°ˆæ¡ˆä¸»ç¨‹å¼è³‡æ–™å¤¾)
 Including another URLconfiguration <br>
    1. Import the include() function: from django.urls import include, path <br>
    2. Add a URL to urlpatterns:  path('blog/', include('blog.urls')) <br>

        # URLconf
        from django.contrib import admin
        from django.urls import path, include
        
        urlpatterns = [
            path('admin/', admin.site.urls),
            path('', include("tickets.urls")),
        ]

>cmd excute: <br>
>>        python manage.py run server<br>
>chrome browser excute:<br>
>>        http://127.0.0.1:8000/tickets


## å»ºç«‹çˆ¬èŸ²
é–‹ç™¼KKDAY ç¶²ç«™çš„ä¸€æ—¥éŠç¥¨åˆ¸è³‡è¨Š
æ¯å€‹è¦çˆ¬èŸ²çš„ç¶²ç«™éƒ½æœƒæœ‰ä¸åŒçš„æ–¹æ³•ï¼Œé‚£æ¯å€‹çˆ¬èŸ²çš„æ–¹æ³•æˆ‘å€‘å°±æŠŠå®ƒæ”¾åœ¨ä¸€å€‹classï¼Œè¶Šå¤šç¶²ç«™å°±è¶Šå¤šclass å»æ“´å……ç¶²ç«™è¦é¡¯ç¤ºçš„è³‡è¨Šã€‚<br>
### scrapers.py(in tickets pockets)
å› ç‚ºé¡¯ç¤ºç¶²ç«™çš„ç¶²é æˆ‘å€‘è¨­å®šåœ¨tickets è³‡æ–™å¤¾ç•¶ä¸­ï¼Œæˆ‘å€‘è¦æ–°å¢scrapers.py <br>
å®šç¾©ä¸€å€‹ç¶²ç«™æŠ½è±¡é¡åˆ¥ï¼Œå…¶ä¸­åŒ…å«åŸå¸‚åç¨±(city_name)å±¬æ€§åŠçˆ¬å–(scrape)æŠ½è±¡æ–¹æ³•

**libraries**

        from abc import ABC, abstractmethod
        from datetime import datetime
        from bs4 import BeautifulSoup
        import time
        import json
        from selenium import webdriver
        from selenium.webdriver.chrome.options import Options
        import pandas as pd


*ç¥¨åˆ¸ç¶²ç«™æŠ½è±¡é¡åˆ¥*
        class Website(ABC):
            
            def __init__(self,city_name):
                self.city_name = city_name # åŸå¸‚åç¨±å±¬æ€§


            @abstractmethod
            def scrape(self):  #çˆ¬å–ç¥¨åˆ¸æŠ½è±¡æ–¹æ³•
                pass

*kkdayç¶²ç«™*
ç”¨selenium é€£æ¥ç¶²è·¯ï¼Œå®šç¾©æœå°‹çš„åŸå¸‚åï¼Œå¦‚æœcity_name ä¸æ˜¯ç©ºçš„ï¼Œå°±å¯ä»¥é€²è¡Œçˆ¬èŸ²ï¼Œå°‡è³‡æ–™å­˜åœ¨dict


    class Kkday(Website):
        #æ–¹æ³•:çˆ¬èŸ²ä¸»ç¨‹å¼
        def scrape(self):
        
            #ä½¿ç”¨seleniumé€£æ¥ç½‘ç»œ
            def selenium_chrome(url):
                option = Options()
                #ä½¿ç”¨ç„¡ç—•æ¨¡å¼
                option.add_argument("--incognito")
                # æ‰“é–‹chromeç¶²é 
                browser = webdriver.Chrome(options=option)
                browser.get(url)

                return browser
             def find_city_id(cityName):

        # å¦‚æœåŸå¸‚å ç­‰æ–¼ cityListç•¶ä¸­çš„åŸå¸‚ï¼Œå¯ä»¥å¾—çŸ¥å…¶åŸå¸‚çš„ i,j,k
        #è¿”å› id çµ¦ç¶²å€
            
            with open("./search.json") as all_script:
                    script = json.load(all_script)
                    data = script['search']['areaData']['zh-tw']['continents']
                    N = len(data) #è¨ˆç®—æœ‰å¤šå°‘æ´²:8
                    cityList =[]
                    # å°‡æ¯å€‹åŸå¸‚çš„id and name æŠ“å‡ºä¾†
                    for i in range(0,N-1):
                        countries = data[i]['countries']
                        J = len(countries) # è¨ˆç®—æ¯ä¸€æ´²(å€åŸŸ)æœ‰å¹¾å€‹åœ‹å®¶:27
                        # print("J :",J)
                        for j in range(0,J-1):
                            cities = countries[j]['cities']
                            K = len(cities) # è¨ˆç®—æ¯å€‹åœ‹å®¶çš„åŸå¸‚æœ‰å¹¾å€‹
                            # print("K:",K)
                            for k in range(0,K-1):
                                id = data[i]['countries'][j]['cities'][k]['id']
                                name = data[i]['countries'][j]['cities'][k]['name']

                                if cityName == name:
                                    print(i,j,k)
                                    print(id)
                                    return id
                                
                            
                            cityList.append([id,name])

        # å¦‚æœcity_name ä¸æ˜¯ç©ºçš„
        if find_city_id(self.city_name):
            result = [] #å›å‚³è³‡æ–™#æ”¶é›†data
            url = "https://www.kkday.com/zh-tw/product/productlist?page=1&city={}&cat=TAG_4_4&sort=prec".format(find_city_id(self.city_name))
            browser = selenium_chrome(url)

            soup = BeautifulSoup(browser.page_source, 'html.parser',on_duplicate_attribute='ignore')
            # å–å¾—è³‡æ–™dict
            data = soup.find_all('div',{'class':"product-listview search-info gtm-prod-card-element"})

            # çˆ¬å–æƒ³è¦çš„è³‡æ–™
            #ã€€æ¨™é¡Œã€é€£çµã€åƒ¹æ ¼ã€å¯ä½¿ç”¨æ—¥æœŸã€è©•åˆ†
            for detail in data:
                title = detail.find('span',{'class':"product-listview__name"}).text
                date = detail.find('div',{'class':"product-time-icon"}).text[-18:-1].replace('\t','').replace('\n','')
                price = detail.find('div',{'class':"product-pricing"}).text.replace('\t','').replace('\n','')
                star = detail.find('span',{'class':"text-grey-light"})
                link= detail.find('a').get('href')
                source = "https://www.kkday.com/favicon.png"

                if star == None:
                    print('none:',type(star))
                else:
                    star = star.text
                    print(type(star))
                # è³‡æ–™ç–ŠåŠ 
                result.append(dict(title= title,date=date,price=price,star=star,link=link,source=source))
                
            return result
        time.sleep(2)

æ‰“åŒ…çš„è³‡æ–™åœ¨ result.appendè£¡é¢ï¼Œå›å‚³åˆ°index.html

                
## å»ºç«‹fronted templete django æ¨£æ¿
### index.html(in tickets/templates/tickets folder)
å°‡poståŠ å…¥ template<br>
å»ºç«‹å‰ç«¯è³‡æ–™POSTå‚³å…¥ticlets/view.py>scrape.py ä¸­çš„class ï¼Œæ‰“åŒ…è³‡æ–™ï¼Œè½‰æˆtickets ç‰©ä»¶å›å‚³åˆ°å‰ç«¯ç¶²é 

        <form id ="city" actin="" method="Post">
          {% csrf_token %}
          <input name="city_name" placeholder="è«‹è¼¸å…¥åŸå¸‚çš„ä¸­æ–‡åç¨±">
          <input type="submit" value="æŸ¥è©¢">
        </form>
        
   *{% csrf_token %} é¿å…è·¨ç«™è«‹æ±‚æ”»æ“Š*     
        
        
### views.py
å°‡å‚³é€éä¾†çš„åŸå¸‚åç¨±é—œéµå­—(city_name)ï¼Œå‚³å…¥Pythonç¶²é çˆ¬èŸ²çš„é¡åˆ¥(Class:kkday)ä¸­ï¼Œsearch city å°æ‡‰çš„ä»£è™Ÿï¼Œé€²è¡Œscrapyï¼Œä¸¦ä¸”å°‡çˆ¬å–çš„çµæœæ‰“åŒ…æˆticketsç‰©ä»¶(Context)å›å‚³çµ¦ç¶²é 
<br>

**Libraries**

        from django.shortcuts import render
        from django.template import loader
        from .scrapers import Kkday

**define**

        def index(request):


        kkday = Kkday(request.POST.get("city_name"))


        context = {
            "tickets" : kkday.scrape()
        }

    return render(request, "tickets/index.html",context)


### index.html
**show table**
        
        <table class="table">
          <thead>
            <tr>
              <th>ç¥¨åˆ¸åç¨±</th>
              <th>åƒ¹æ ¼</th>
              <th>æœ€æ—©å¯ä½¿ç”¨æ—¥æœŸ</th>
              <th>è©•åƒ¹</th>
              <th>ä¾†æºç¶²ç«™</th>
            </tr>
          </thead>
          <tbody>
            {% for ticket in tickets %}
            <tr>
              <td>
                <a href="{{ticket.link}}" target="_blank">{{ ticket.title }}</a>
              </td>
              <td>{{ticket.price}}</td>
              <td>{{ticket.date}}</td>
              <td>{{ticket.star}}</td>
              <td><img src={{ticket.source}} style="width: 32px;height: 32px;"/></td>
            </tr>
        
            {% endfor %}
          </tbody>

ğŸ“ **Note:** Only scrapy kkdaywebside 
